
x-airflow-common: &airflow-common
  build:
    context: ./docker_image/airflow
    dockerfile: ./Dockerfile
  env_file:
    - ./docker_image/airflow/airflow.env
  volumes:
    - ./airflow/jobs:/opt/airflow/jobs
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/jars:/opt/airflow/jars
    - /var/run/docker.sock:/var/run/docker.sock
  depends_on:
    - postgres

services:
  mariadb:
    hostname: mariadb
    image: mariadb:10.5.16
    ports:
      - 3306:3306
    env_file: .env
    volumes:
      - mariadb:/var/lib/mysql

  # Hive metastore
  hive-metastore:
    hostname: hive-metastore
    image: "bitsondatadev/hive-metastore:latest"
    ports:
      - "9083:9083" # Metastore Thrift
    volumes:
      - ./data_lakehouse/conf/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    env_file: .env
    depends_on:
      - mariadb

  trino-450:
    hostname: trino-450
    image: "trinodb/trino:450"
    ports:
      - "8082:8080"
    volumes:
      - ./data_lakehouse/etc:/etc/trino
    depends_on:
      - minio
      - hive-metastore

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always

  spark-master:
    build:
      context: ./docker_image/spark
      dockerfile: ./Dockerfile
    container_name: "spark-master-movies"
    ports:
      - "7077:7077" # Spark master port
      - "8081:8080" # Spark master web UI port
    expose:
      - "7077"
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    volumes:
      - ./docker_image/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./docker_image/spark/conf/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
      - ./data:/opt/spark


  spark-worker-1:
    image: docker.io/bitnami/spark:3.3.2
    container_name: "spark-worker-1-movies"
    env_file:
      - .env
    depends_on:
      - spark-master
    restart: always

  minio:
    hostname: minio
    image: "minio/minio:latest"
    container_name: minio-movies
    ports:
      - "9001:9001"
      - "9000:9000"
    volumes:
      - minio:/data
    env_file: .env
    command: ["server", "/data", "--console-address", ":9001"]
    # UI dashboard
  superset:
    build:
      context: ./docker_image/superset
      dockerfile: ./Dockerfile
    container_name: Superset-movies
    env_file:
      - .env
    ports:
      - "8088:8088"
    volumes:
      - superset_home:/app/superset_home

  webserver-1:
    <<: *airflow-common
    command: webserver
    ports:
      - "8085:8080"
    depends_on:
      - scheduler

  scheduler:
    <<: *airflow-common
    command: bash -c "airflow db migrate && airflow users create --username admin --firstname Yusuf --lastname Ganiyu --role Admin --email airscholar@gmail.com --password admin && airflow scheduler"
  

  jupyter:
    build:
      context: ./docker_image/jupyter
      dockerfile: ./Dockerfile
    container_name: jupyter
    ports:
      - "8888:8888"   # Jupyter Notebook
      - "8501:8501" 
    volumes:
      - ./jupyter/notebooks:/home/jovyan/work
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    depends_on:
      - spark-master



      
  zookeeper:
    image: bitnami/zookeeper:3.9
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes" # Cho phép kết nối không xác thực
    volumes:
      - zookeeper_data:/bitnami/zookeeper

  kafka:
    image: bitnami/kafka:3.9.0
    hostname: kafka
    ports:
      - "9092:9092"
      - "29092:29092" # Port cho kết nối từ host
    environment:
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,PLAINTEXT_HOST://:29092
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CFG_BROKER_ID: 1
    volumes:
      - kafka_data:/bitnami/kafka
    depends_on:
      - zookeeper



  tmdb-crawler:
    profiles: ["manual"]
    build:
      context: ./docker_image/tmdb_crawler
      dockerfile: Dockerfile
    container_name: tmdb-crawler_Daily
    volumes:
      - ./docker_image/tmdb_crawler:/app
    depends_on:
      - kafka
    networks:
      - default



  tmdb-crawler-all:
    profiles: ["manual"]
    build:
      context: ./docker_image/tmdb_crawler_All
      dockerfile: Dockerfile
    container_name: tmdb-crawler_All
    volumes:
      - ./docker_image/tmdb_crawler_All:/app
    depends_on:
      - kafka
    networks:
      - default

volumes:
  postgres-db-volume:
  minio:
  airflow-data:
  mariadb:
  superset_home:
  zookeeper_data: # Thêm volume cho Zookeeper
  kafka_data:     # Thêm volume cho Kafka

networks:
  default:
    driver: bridge
