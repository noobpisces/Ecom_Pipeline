{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45ee05f-90d9-4a49-8750-16d5e09aaf2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, BooleanType, StringType, IntegerType, DateType, FloatType,DoubleType,ArrayType,LongType\n",
    "import logging\n",
    "import sys\n",
    "import traceback\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr,when,to_date ,udf, concat_ws,posexplode, from_json\n",
    "from pyspark.sql.types import StructType, StructField, BooleanType, StringType, IntegerType, DateType, FloatType,DoubleType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df4a87b-b37a-4373-9d8e-b43a89a2198f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MinIO with Delta Lake\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\")  \\\n",
    "    .config(\"spark.jars\", \"jars/hadoop-aws-3.3.4.jar,jars/spark-sql-kafka-0-10_2.12-3.2.1.jar,jars/aws-java-sdk-bundle-1.12.262.jar,jars/delta-core_2.12-2.2.0.jar,jars/delta-storage-2.2.0.jar\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"conbo123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"123conbo\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.delta.logStore.class\", \"org.apache.spark.sql.delta.storage.S3SingleDriverLogStore\") \\\n",
    "    .config(\"delta.enable-non-concurrent-writes\", \"true\") \\\n",
    "    .config('spark.sql.warehouse.dir', \"s3a://lakehouse/\") \\\n",
    "    .config(\"spark.sql.pivotMaxValues\", 100000) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9fb012-31d9-4478-b3a4-13ea4100369f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.7133187272049824\n",
      "+-------+------------------------+---------+\n",
      "|movieId|title                   |rating   |\n",
      "+-------+------------------------+---------+\n",
      "|65     |8 Mile                  |4.2972136|\n",
      "|78     |Blade Runner            |3.9369345|\n",
      "|85     |Raiders of the Lost Ark |4.7445807|\n",
      "|108    |Three Colors: Blue      |3.8384032|\n",
      "|133    |Primary                 |3.5303516|\n",
      "|137    |Groundhog Day           |5.419944 |\n",
      "|148    |The Secret Life of Words|5.282393 |\n",
      "|155    |The Dark Knight         |5.053992 |\n",
      "|193    |Star Trek: Generations  |4.5696354|\n",
      "|211    |Berlin is in Germany    |4.4432755|\n",
      "+-------+------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Đọc dữ liệu movie_names và ratings_data từ Delta\n",
    "movie_names = spark.read.format(\"delta\").load(\"s3a://lakehouse/gold/dim_movie\")\n",
    "movie_names = movie_names.select(\"id\", \"title\")\n",
    "movie_names = movie_names.withColumnRenamed(\"id\", \"movieId\")\n",
    "\n",
    "ratings_data = spark.read.format(\"delta\").load(\"s3a://lakehouse/silver/ratings\")\n",
    "ratings_data = ratings_data.select(\"userId\", \"movieId\", \"rating\")\n",
    "ratings_data = ratings_data.limit(500000)\n",
    "\n",
    "# Kết hợp dữ liệu ratings và movie names\n",
    "ratings_data_with_names = ratings_data.join(movie_names, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "# Hiển thị các trường dữ liệu cơ bản\n",
    "# ratings_data_with_names.show(5)\n",
    "\n",
    "# Xây dựng mô hình ALS\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\", nonnegative=True)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model = als.fit(ratings_data)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "predictions = model.transform(ratings_data)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error = {rmse}\")\n",
    "\n",
    "# Dự đoán các bộ phim mà người dùng chưa xem\n",
    "user_recommendations = model.recommendForAllUsers(10)\n",
    "\n",
    "# Hiển thị các gợi ý cho một người dùng cụ thể (userId = 1)\n",
    "# user_recommendations.filter(user_recommendations.userId == 1).show(10)\n",
    "\n",
    "# Lấy ra các bộ phim gợi ý cho một bộ phim cụ thể (movieId = 1)\n",
    "# Dự đoán các phim mà người dùng có thể yêu thích dựa trên các bộ phim mà họ đã xem\n",
    "similar_movies = model.recommendForAllItems(10)\n",
    "\n",
    "# Hiển thị các gợi ý cho bộ phim cụ thể (movieId = 1)\n",
    "# similar_movies.filter(similar_movies.movieId == 1).show(10)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# # Hàm lấy movieId từ tên bộ phim\n",
    "# from pyspark.sql import functions as F\n",
    "\n",
    "# # Hàm lấy movieId từ tên bộ phim\n",
    "# def get_movie_id_by_name(title):\n",
    "#     movie = movie_names.filter(movie_names.title == title).collect()\n",
    "#     return movie[0]['movieId'] if movie else None\n",
    "\n",
    "# # Ví dụ: tìm các bộ phim tương tự với \"Toy Story\"\n",
    "# movie_name = \"Toy Story\"\n",
    "# movie_id = get_movie_id_by_name(movie_name)\n",
    "\n",
    "# # Nếu tìm thấy movieId, lấy gợi ý\n",
    "# if movie_id:\n",
    "#     # Lọc các bộ phim tương tự với movieId đã cho\n",
    "#     similar_movies_for_input = similar_movies.filter(similar_movies.movieId == movie_id)\n",
    "\n",
    "#     # \"Explode\" recommendations để lấy từng bộ phim trong mảng\n",
    "#     exploded_recommendations = similar_movies_for_input.withColumn(\n",
    "#         \"recommendation\", F.explode(\"recommendations\")\n",
    "#     )\n",
    "\n",
    "#     # Access movieId and other fields from the exploded recommendations (recommendation.userId, recommendation.rating)\n",
    "#     exploded_recommendations = exploded_recommendations.select(\n",
    "#         F.col(\"movieId\"),\n",
    "#         F.col(\"recommendation.userId\").alias(\"userId\"),\n",
    "#         F.col(\"recommendation.rating\").alias(\"rating\")\n",
    "#     )\n",
    "\n",
    "#     # Hiển thị movieId cùng với các thông tin người dùng và rating\n",
    "#     exploded_recommendations.show(truncate=False)\n",
    "# else:\n",
    "#     print(\"Movie not found!\")\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Hàm lấy movieId từ tên bộ phim\n",
    "def get_movie_id_by_name(title):\n",
    "    movie = movie_names.filter(movie_names.title == title).collect()\n",
    "    return movie[0]['movieId'] if movie else None\n",
    "\n",
    "# Ví dụ: nhập tên bộ phim để tìm các gợi ý tương tự\n",
    "movie_name = \"Toy Story\"  # Thay tên bộ phim tại đây\n",
    "movie_id = get_movie_id_by_name(movie_name)\n",
    "\n",
    "# Nếu tìm thấy movieId, lấy gợi ý\n",
    "if movie_id:\n",
    "    # Lọc các bộ phim tương tự với movieId đã cho từ mô hình ALS (recommendForAllItems)\n",
    "    # Lấy ra 10 bộ phim gợi ý\n",
    "    similar_movies = model.recommendForAllItems(10)  # Lấy ra 10 bộ phim gợi ý\n",
    "    \n",
    "    # Lọc các bộ phim có movieId khác với movie_id đã tìm\n",
    "    similar_movies_for_input = similar_movies.filter(similar_movies.movieId != movie_id)\n",
    "\n",
    "    # \"Explode\" recommendations để lấy từng bộ phim trong mảng\n",
    "    exploded_recommendations = similar_movies_for_input.withColumn(\n",
    "        \"recommendation\", F.explode(\"recommendations\")\n",
    "    )\n",
    "\n",
    "    # Lấy ra movieId và rating của các bộ phim được gợi ý\n",
    "    exploded_recommendations = exploded_recommendations.select(\n",
    "        F.col(\"movieId\"), \n",
    "        F.col(\"recommendation.rating\").alias(\"rating\")\n",
    "    )\n",
    "\n",
    "    # Kết hợp với tên bộ phim từ bảng movie_names\n",
    "    movie_with_names = exploded_recommendations.join(movie_names, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "    # Lọc kết quả để chỉ lấy 10 bộ phim gợi ý duy nhất\n",
    "    unique_movie_suggestions = movie_with_names.dropDuplicates([\"movieId\"]).limit(10)\n",
    "\n",
    "    # Hiển thị kết quả: movieId, title và rating của các bộ phim gợi ý\n",
    "    unique_movie_suggestions.select(\"movieId\", \"title\", \"rating\").show(truncate=False)\n",
    "else:\n",
    "    print(\"Movie not found!\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
