{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3faed848-6cf4-4740-8253-46200247bb7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, BooleanType, StringType, IntegerType, DateType, FloatType,DoubleType,ArrayType,LongType\n",
    "import logging\n",
    "import sys\n",
    "import traceback\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr,when,to_date ,udf, concat_ws,posexplode, from_json\n",
    "from pyspark.sql.types import StructType, StructField, BooleanType, StringType, IntegerType, DateType, FloatType,DoubleType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ecb2eb-c351-4005-9f59-c520ca278f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MinIO with Delta Lake\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"5g\") \\\n",
    "    .config(\"spark.executor.cores\", \"3\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\", \"1\") \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"1\") \\\n",
    "    .config(\"spark.dynamicAllocation.initialExecutors\", \"1\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"12\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"1g\") \\\n",
    "    .config(\"spark.jars\", \"jars/hadoop-aws-3.3.4.jar,jars/spark-sql-kafka-0-10_2.12-3.2.1.jar,jars/aws-java-sdk-bundle-1.12.262.jar,jars/delta-core_2.12-2.2.0.jar,jars/delta-storage-2.2.0.jar\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"conbo123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"123conbo\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.delta.logStore.class\", \"org.apache.spark.sql.delta.storage.S3SingleDriverLogStore\") \\\n",
    "    .config(\"delta.enable-non-concurrent-writes\", \"true\") \\\n",
    "    .config('spark.sql.warehouse.dir', \"s3a://lakehouse/\") \\\n",
    "    .config(\"spark.sql.pivotMaxValues\", \"100000\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda4a118-69c0-47d0-afcf-8036d97f3c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import numpy as np\n",
    "import time\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col, mean, lit, udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.recommendation import ALSModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbed0c92-a338-4a24-8a25-2ff4b16da51c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu từ Delta\n",
    "movies = spark.read.format(\"delta\").load(\"s3a://lakehouse/gold/dim_movie\")\n",
    "movies = movies.select(\"id\", \"title\")\n",
    "movies = movies.withColumnRenamed(\"id\", \"movieId\")\n",
    "\n",
    "ratings = spark.read.format(\"delta\").load(\"s3a://lakehouse/silver/ratings\")\n",
    "ratings = ratings.select(\"userId\", \"movieId\", \"rating\")\n",
    "# ratings = ratings.limit(1000000)\n",
    "\n",
    "# Chuyển đổi kiểu dữ liệu\n",
    "df = ratings.withColumn('userId', ratings['userId'].cast('int')).\\\n",
    "    withColumn('movieId', ratings['movieId'].cast('int')).withColumn('rating', ratings['rating'].cast('float'))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93314a80-c414-473a-8108-8d00328ebacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hàm tính RMSE\n",
    "def RMSE(predictions):\n",
    "    predictions = predictions.withColumn(\"squared_error\", (F.col(\"rating\") - F.col(\"prediction\")) ** 2)\n",
    "    return predictions.agg(F.sqrt(F.mean(\"squared_error\"))).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c7ee7d-5615-4015-ba8a-20c7bd04a52b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merge = None\n",
    "df_list = None\n",
    "flag1 = False\n",
    "flag2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b1f53de-9f3d-478e-a650-07c85895f110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vecs():\n",
    "    global df_list, all_vecs, flag2\n",
    "    if not flag2:\n",
    "        df_list = spark.read.format(\"delta\").load(\"s3a://lakehouse/data/all_movies_delta\")\n",
    "        data_original = df_list.collect()\n",
    "        all_vecs = [(row.id, Vectors.dense(row.vecs)) for row in data_original]\n",
    "        flag2 = True\n",
    "    return all_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "268ecaca-5c2c-4f56-8a9a-27c33de8072e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hàm tính toán Cosine Similarity (Content-Based)\n",
    "def CosineSim(vec1, vec2):\n",
    "    numerator = np.dot(vec1, vec2)\n",
    "    denominator = np.sqrt(np.dot(vec1, vec1)) * np.sqrt(np.dot(vec2, vec2))\n",
    "    return float(numerator / denominator) if denominator != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35f4fa-8edb-4627-8160-6aed59c23be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b51d521-70ac-411b-bb22-a30141d9f68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3414455d-132f-45a8-9d05-2b4d71fbfc8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cb_recommendations(m_title,sim_mov_limit =50):\n",
    "    global df_merge\n",
    "    df_merge = spark.read.format(\"delta\").load(\"s3a://lakehouse/merge_data-movies/merged_data\")\n",
    "    \n",
    "    # Kiểm tra xem phim có trong cơ sở dữ liệu không\n",
    "    if df_merge.filter(F.col(\"title\") == m_title).count() == 0:\n",
    "        return \"Sorry! The movie you searched is not in our database. Please check the spelling or try another movie.\"\n",
    "    \n",
    "    # Lấy vector đặc trưng của các bộ phim\n",
    "    all_movies_vecs = get_vecs()\n",
    "    \n",
    "    # Lấy movieId của phim nhập vào\n",
    "    m_id = df_merge.filter(F.col(\"title\") == m_title).select(F.col('id')).collect()[0][0]\n",
    "    \n",
    "    # Lấy vector của bộ phim đã nhập\n",
    "    input_vec = [r[1] for r in all_movies_vecs if r[0] == m_id][0]\n",
    "    \n",
    "    # Tính độ tương đồng cosine giữa các phim\n",
    "    similar_movies_rdd = spark.sparkContext.parallelize(\n",
    "        [(i[0], CosineSim(input_vec, i[1])) for i in all_movies_vecs]\n",
    "    )\n",
    "    \n",
    "    # Chuyển kết quả sang DataFrame và sắp xếp theo độ tương đồng\n",
    "    similar_movies_df = spark.createDataFrame(similar_movies_rdd, [\"movies_id\", \"score\"]) \\\n",
    "        .orderBy(F.col(\"score\").desc()) \\\n",
    "        .filter(F.col(\"movies_id\") != m_id) \\\n",
    "        .limit(sim_mov_limit)\n",
    "    \n",
    "    similar_movies_df = similar_movies_df.withColumn(\"input_movies_id\", lit(m_id))\n",
    "    \n",
    "    # Đổi tên cột 'movies_id' thành 'movieId' để phù hợp với cột của DataFrame CF\n",
    "    similar_movies_df = similar_movies_df.withColumnRenamed(\"movies_id\", \"movieId\")\n",
    "    \n",
    "    return similar_movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c7c38d-45bd-4ec2-bba4-8edb72d2162b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def hybrid_recommendation(user_id, m_title, sim_mov_limit, sim_weight, cf_weight):\n",
    "#     # Gợi ý Content-Based\n",
    "#     cb_recommendations = get_cb_recommendations(m_title, sim_mov_limit)\n",
    "\n",
    "#     # Lấy thông tin tên phim từ bảng movies\n",
    "#     movies_df = spark.read.format(\"delta\").load(\"s3a://lakehouse/gold/dim_movie\").select(\n",
    "#         F.col(\"id\").alias(\"movieId\"), \"title\"\n",
    "#     )\n",
    "\n",
    "#     # Kiểm tra nếu cb_recommendations trả về thông báo lỗi\n",
    "#     if isinstance(cb_recommendations, str):\n",
    "#         return cb_recommendations\n",
    "\n",
    "#     # Kiểm tra user có tồn tại trong tập train hay không\n",
    "#     user_in_train = train.filter(train['userId'] == user_id).count() > 5\n",
    "#     if not user_in_train:\n",
    "#         print(f\"User {user_id} không không đủ điều kiện => sử dụng Content-Based.\")\n",
    "#         return cb_recommendations.join(movies_df, on=\"movieId\", how=\"inner\") \\\n",
    "#                                  .select(\"movieId\", \"title\", F.col(\"score\").alias(\"hybrid_score\"))\n",
    "\n",
    "#     # Lấy danh sách các phim chưa xem (dựa trên tập train)\n",
    "#     all_movies = df.select('movieId').distinct()\n",
    "#     user_movies = train.filter(train['userId'] == user_id).select('movieId').distinct()\n",
    "#     movies_to_recommend = all_movies.subtract(user_movies)\n",
    "\n",
    "#     # Dự đoán với CF\n",
    "#     recommendations_cf = final_model.transform(movies_to_recommend.withColumn('userId', F.lit(user_id)))\n",
    "#     recommendations_cf = recommendations_cf.filter(F.col('prediction').isNotNull() & (F.col('prediction') > 0))\n",
    "\n",
    "#     # Gán tên cột để phân biệt điểm số\n",
    "#     cb_recommendations = cb_recommendations.withColumn(\"score_cb\", F.col(\"score\"))\n",
    "#     recommendations_cf = recommendations_cf.withColumn(\"score_cf\", F.col(\"prediction\"))\n",
    "\n",
    "#     # Kết hợp hai nguồn\n",
    "#     hybrid_recommendations = cb_recommendations.join(recommendations_cf, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "#     # Join với bảng movie để lấy tiêu đề\n",
    "#     hybrid_recommendations = hybrid_recommendations.join(movies_df, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "#     # Tính điểm kết hợp\n",
    "#     hybrid_recommendations = hybrid_recommendations.withColumn(\n",
    "#         \"hybrid_score\",\n",
    "#         sim_weight * F.col(\"score_cb\") + cf_weight * F.col(\"score_cf\")\n",
    "#     )\n",
    "\n",
    "#     # Trả kết quả\n",
    "#     return hybrid_recommendations.select(\"movieId\", \"title\", \"hybrid_score\") \\\n",
    "#                                  .orderBy(F.col(\"hybrid_score\").desc())\n",
    "\n",
    "\n",
    "def hybrid_recommendation(user_id, m_title, sim_weight, cf_weight):\n",
    "    cb_recommendations = get_cb_recommendations(m_title)\n",
    "\n",
    "    movies_df = spark.read.format(\"delta\").load(\"s3a://lakehouse/merge_data-movies/merged_data\") \\\n",
    "        .select(F.col(\"id\").cast(\"int\").alias(\"movieId\"), \"title\")\n",
    "\n",
    "    if isinstance(cb_recommendations, str):\n",
    "        return cb_recommendations\n",
    "\n",
    "    user_in_train = train.filter(train['userId'] == user_id).count() > 5\n",
    "    if not user_in_train:\n",
    "        print(f\"User {user_id} không đủ điều kiện => sử dụng Content-Based.\")\n",
    "        return cb_recommendations.join(movies_df, on=\"movieId\", how=\"left\") \\\n",
    "                                 .select(\"movieId\", \"title\", F.col(\"score\").alias(\"hybrid_score\"))\n",
    "\n",
    "    all_movies = df.select('movieId').distinct()\n",
    "    user_movies = train.filter(train['userId'] == user_id).select('movieId').distinct()\n",
    "    movies_to_recommend = all_movies.subtract(user_movies)\n",
    "    temp = ALSModel.load(\"s3a://lakehouse/CF/als_best_model\")\n",
    "    recommendations_cf = temp.transform(movies_to_recommend.withColumn('userId', F.lit(user_id)))\n",
    "    recommendations_cf = recommendations_cf.filter(F.col('prediction').isNotNull() & (F.col('prediction') > 0)) \\\n",
    "                                           .withColumnRenamed(\"prediction\", \"score_cf\")\n",
    "                                                                    \n",
    "    cb_recommendations = cb_recommendations.withColumnRenamed(\"score\", \"score_cb\")\n",
    "    cb_recommendations = cb_recommendations.withColumn(\"movieId\", F.col(\"movieId\").cast(\"int\"))\n",
    "\n",
    "    # joined_df = cb_recommendations.join(recommendations_cf, on=\"movieId\", how=\"outer\")\n",
    "    # joined_df.filter(F.col(\"score_cb\").isNotNull()).show() \n",
    "\n",
    "\n",
    "    # ⚠️ Outer join để giữ lại cả phim chỉ có ở 1 nguồn\n",
    "    hybrid_recommendations = cb_recommendations.join(recommendations_cf, on=\"movieId\", how=\"outer\")\n",
    "    hybrid_recommendations = hybrid_recommendations.filter(F.col(\"score_cb\").isNotNull())\n",
    "    # Tính điểm kết hợp có điều kiện\n",
    "    hybrid_recommendations = hybrid_recommendations.withColumn(\n",
    "        \"hybrid_score\",\n",
    "        F.when(F.col(\"score_cb\").isNotNull() & F.col(\"score_cf\").isNotNull(),\n",
    "               sim_weight * F.col(\"score_cb\") + cf_weight * F.col(\"score_cf\"))\n",
    "         .when(F.col(\"score_cb\").isNotNull(), F.col(\"score_cb\"))\n",
    "         .otherwise(F.col(\"score_cf\"))\n",
    "    )\n",
    "\n",
    "    hybrid_recommendations = hybrid_recommendations.join(movies_df, on=\"movieId\", how=\"inner\")\n",
    "    return hybrid_recommendations.select(\"movieId\", \"title\", \"score_cb\", \"score_cf\", \"hybrid_score\") \\\n",
    "                                 .orderBy(F.col(\"hybrid_score\").desc()).limit(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dfa3df9-cf2b-45c6-bfad-873d6f14ec8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+---------+------------------+\n",
      "|movieId|             title|          score_cb| score_cf|      hybrid_score|\n",
      "+-------+------------------+------------------+---------+------------------+\n",
      "|    185|A Clockwork Orange|0.9406853119084989|3.1617157|2.2733035723189414|\n",
      "|    170|     28 Days Later|0.9786354691088911|3.0811553|2.2401473677277846|\n",
      "|   5876|          The Mist|0.9622204895486176|2.9214437|2.1377544162936903|\n",
      "|    281|      Strange Days|0.9595120629139977| 2.793185|2.0597158225563463|\n",
      "|  48385|Indestructible Man|0.9379811621588382|2.6539543| 1.967565025364634|\n",
      "|    754|          Face/Off|0.9367997084469001| 2.583702|1.9249411358201662|\n",
      "|   1562|    28 Weeks Later|0.9684669484449843| 2.519845|1.8992937846880522|\n",
      "|   3509|  A Scanner Darkly|0.9540791103841367|2.4025085|1.8231367424965501|\n",
      "|    167|             K-PAX|0.9466598252287608|2.3705876|1.8010164825054447|\n",
      "|   3162|      Blackenstein|0.9419374601305377|2.2431684|1.7226759964728693|\n",
      "+-------+------------------+------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bước 5: Hiển thị gợi ý phim cho người dùng\n",
    "user_id = 25\n",
    "movie_title = \"The Box\"  # Ví dụ phim mà người dùng yêu thích\n",
    "\n",
    "hybrid_recs = hybrid_recommendation(user_id, movie_title, sim_weight=0.4, cf_weight=0.6)\n",
    "hybrid_recs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f1cb24b-aeb2-4cbf-8897-c2c36f85d2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"class\": \"org.apache.spark.ml.recommendation.ALSModel\",\n",
      "    \"timestamp\": 1744621090009,\n",
      "    \"sparkVersion\": \"3.3.2\",\n",
      "    \"uid\": \"ALS_bfa7aac9dc3e\",\n",
      "    \"paramMap\": {\n",
      "        \"userCol\": \"userId\",\n",
      "        \"coldStartStrategy\": \"drop\",\n",
      "        \"itemCol\": \"movieId\",\n",
      "        \"blockSize\": 4096\n",
      "    },\n",
      "    \"defaultParamMap\": {\n",
      "        \"userCol\": \"user\",\n",
      "        \"coldStartStrategy\": \"nan\",\n",
      "        \"itemCol\": \"item\",\n",
      "        \"blockSize\": 4096,\n",
      "        \"predictionCol\": \"prediction\"\n",
      "    },\n",
      "    \"rank\": 12\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load raw JSON\n",
    "metadata_path = \"s3a://lakehouse/CF/als_best_model/metadata/part-00000\"\n",
    "metadata_raw = spark.sparkContext.textFile(metadata_path).collect()\n",
    "metadata_dict = json.loads(metadata_raw[0])\n",
    "\n",
    "# In thông tin\n",
    "print(json.dumps(metadata_dict, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
